{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter.ttk import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use cuda, or not? be prepared for a long wait if you don't have cuda capabilities.\n",
    "use_cuda = False\n",
    "#input image. the architectures have been designed for 512x512 colour images\n",
    "#proportion of pixels to black out.\n",
    "#ground_truth_path='earth.jpg'\n",
    "prop = 0.5\n",
    "#standard deviation Nof added noise after each training set\n",
    "sigma = 1./30\n",
    "#number of training iterations\n",
    "num_steps = 25001\n",
    "#number of steps to take before saving an output image\n",
    "save_frequency = 250\n",
    "#where to put the output\n",
    "output_name = 'output/output'\n",
    "#choose deconv as the architecture used.\n",
    "method = 'deconv'\n",
    "#accept a file path to a jpg, return a torch tensor\n",
    "def jpg_to_tensor(ground_truth_path):\n",
    "    pil = Image.open(ground_truth_path)\n",
    "    pil_to_tensor = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "    if use_cuda:\n",
    "        tensor = pil_to_tensor(pil).cuda()\n",
    "    else:\n",
    "        tensor = pil_to_tensor(pil)\n",
    "    return tensor.view([1]+list(tensor.shape))\n",
    "\n",
    "#accept a torch tensor, convert it to a jpg at a certain path\n",
    "def tensor_to_jpg(tensor, filename):\n",
    "    tensor = tensor.view(tensor.shape[1:])\n",
    "    if use_cuda:\n",
    "        tensor = tensor.cpu()\n",
    "    tensor_to_pil = torchvision.transforms.Compose([torchvision.transforms.ToPILImage()])\n",
    "    pil = tensor_to_pil(tensor)\n",
    "    pil.save(filename)\n",
    "\n",
    "#function which zeros out a random proportion of pixels from an image tensor.\n",
    "def zero_out_pixels(tensor, prop=prop):\n",
    "    if use_cuda:\n",
    "        mask = torch.rand([1]+[1] + list(tensor.shape[2:])).cuda()\n",
    "    else:\n",
    "        mask = torch.rand([1]+[1] + list(tensor.shape[2:]))\n",
    "    mask[mask<prop] = 0\n",
    "    mask[mask!=0] = 1\n",
    "    mask = mask.repeat(1,3,1,1)\n",
    "    deconstructed = tensor * mask\n",
    "    return mask, deconstructed\n",
    "\n",
    "\n",
    "#define an encoder decoder network with convolution transpose upsampling.\n",
    "class deconv_hourglass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(deconv_hourglass, self).__init__()\n",
    "        self.d_conv_1 = nn.Conv2d(3, 8, 5, stride=2, padding=2)\n",
    "        self.d_bn_1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.d_conv_2 = nn.Conv2d(8, 16, 5, stride=2, padding=2)\n",
    "        self.d_bn_2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.d_conv_3 = nn.Conv2d(16, 32, 5, stride=2, padding=2)\n",
    "        self.d_bn_3 = nn.BatchNorm2d(32)\n",
    "        self.s_conv_3 = nn.Conv2d(32, 4, 5, stride=1, padding=2)\n",
    "\n",
    "        self.d_conv_4 = nn.Conv2d(32, 64, 5, stride=2, padding=2)\n",
    "        self.d_bn_4 = nn.BatchNorm2d(64)\n",
    "        self.s_conv_4 = nn.Conv2d(64, 4, 5, stride=1, padding=2)\n",
    "\n",
    "        self.d_conv_5 = nn.Conv2d(64, 128, 5, stride=2, padding=2)\n",
    "        self.d_bn_5 = nn.BatchNorm2d(128)\n",
    "        self.s_conv_5 = nn.Conv2d(128, 4, 5, stride=1, padding=2)\n",
    "\n",
    "        self.d_conv_6 = nn.Conv2d(128, 256, 5, stride=2, padding=2)\n",
    "        self.d_bn_6 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.u_deconv_5 = nn.ConvTranspose2d(256, 124, 4, stride=2, padding=1)\n",
    "        self.u_bn_5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.u_deconv_4 = nn.ConvTranspose2d(128, 60, 4, stride=2, padding=1)\n",
    "        self.u_bn_4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.u_deconv_3 = nn.ConvTranspose2d(64, 28, 4, stride=2, padding=1)\n",
    "        self.u_bn_3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.u_deconv_2 = nn.ConvTranspose2d(32, 16, 4, stride=2, padding=1)\n",
    "        self.u_bn_2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.u_deconv_1 = nn.ConvTranspose2d(16, 8, 4, stride=2, padding=1)\n",
    "        self.u_bn_1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.out_deconv = nn.ConvTranspose2d(8, 3, 4, stride=2, padding=1)        \n",
    "        self.out_bn = nn.BatchNorm2d(3)\n",
    "\n",
    "        \n",
    "    def forward(self, noise):\n",
    "        down_1 = self.d_conv_1(noise)\n",
    "        down_1 = self.d_bn_1(down_1)\n",
    "        down_1 = F.leaky_relu(down_1)\n",
    "        \n",
    "        down_2 = self.d_conv_2(down_1)\n",
    "        down_2 = self.d_bn_2(down_2)\n",
    "        down_2 = F.leaky_relu(down_2)\n",
    "\n",
    "        down_3 = self.d_conv_3(down_2)\n",
    "        down_3 = self.d_bn_3(down_3)\n",
    "        down_3 = F.leaky_relu(down_3)\n",
    "        skip_3 = self.s_conv_3(down_3)\n",
    "\n",
    "        down_4 = self.d_conv_4(down_3)\n",
    "        down_4 = self.d_bn_4(down_4)\n",
    "        down_4 = F.leaky_relu(down_4)\n",
    "        skip_4 = self.s_conv_4(down_4)\n",
    "\n",
    "        down_5 = self.d_conv_5(down_4)\n",
    "        down_5 = self.d_bn_5(down_5)\n",
    "        down_5 = F.leaky_relu(down_5)\n",
    "        skip_5 = self.s_conv_5(down_5)\n",
    "\n",
    "        down_6 = self.d_conv_6(down_5)\n",
    "        down_6 = self.d_bn_6(down_6)\n",
    "        down_6 = F.leaky_relu(down_6)\n",
    "\n",
    "        up_5 = self.u_deconv_5(down_6)\n",
    "        up_5 = torch.cat([up_5, skip_5], 1)\n",
    "        up_5 = self.u_bn_5(up_5)\n",
    "        up_5 = F.leaky_relu(up_5)\n",
    "\n",
    "        up_4 = self.u_deconv_4(up_5)\n",
    "        up_4 = torch.cat([up_4, skip_4], 1)\n",
    "        up_4 = self.u_bn_4(up_4)\n",
    "        up_4 = F.leaky_relu(up_4)\n",
    "\n",
    "        up_3 = self.u_deconv_3(up_4)\n",
    "        up_3 = torch.cat([up_3, skip_3], 1)\n",
    "        up_3 = self.u_bn_3(up_3)\n",
    "        up_3 = F.leaky_relu(up_3)\n",
    "\n",
    "        up_2 = self.u_deconv_2(up_3)\n",
    "        up_2 = self.u_bn_2(up_2)\n",
    "        up_2 = F.leaky_relu(up_2)\n",
    "\n",
    "        up_1 = self.u_deconv_1(up_2)\n",
    "        up_1 = self.u_bn_1(up_1)\n",
    "        up_1 = F.leaky_relu(up_1)\n",
    "\n",
    "        out = self.out_deconv(up_1)\n",
    "        out = self.out_bn(out)\n",
    "        out = F.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "#Function to open the file\n",
    "def openfile():\n",
    "    #Distorted Image\n",
    "    ground_truth_path = askopenfilename(filetypes=[(\"Image File\",['.jpg','.JPG'])])\n",
    "    #input image. the architectures have been designed for 512x512 colour images\n",
    "    basewidth = 512\n",
    "    img = Image.open(ground_truth_path)\n",
    "    #wpercent = (basewidth / float(img.size[0]))\n",
    "    #hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "    img = img.resize((basewidth, basewidth), PIL.Image.ANTIALIAS)\n",
    "    img.save(ground_truth_path)\n",
    "    print(ground_truth_path)\n",
    "    truth = jpg_to_tensor(ground_truth_path)\n",
    "    #deconstruct image\n",
    "    mask, deconstructed = zero_out_pixels(truth)\n",
    "    #save the deconstructed image\n",
    "    tensor_to_jpg(deconstructed, 'earthdest.jpg')\n",
    "    #convert the image and mask to variables.\n",
    "    mask = Variable(mask)\n",
    "    \n",
    "    deconstructed = Variable(deconstructed)\n",
    "\n",
    "    #input of the network is noise\n",
    "    if use_cuda:\n",
    "        noise = Variable(torch.randn(deconstructed.shape).cuda())\n",
    "    else:\n",
    "        noise = Variable(torch.randn(deconstructed.shape))\n",
    "\n",
    "    #initialise the network with the chosen architecture\n",
    "    if method=='deconv':\n",
    "        net = deconv_hourglass()\n",
    "    \n",
    "    #bind the network to the gpu if cuda is enabled\n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "    #network optimizer set up\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "    # pgbar = Toplevel()\n",
    "    # pgbar.geometry('500x500')\n",
    "    # progress = Progressbar(pgbar, length=100,orient = HORIZONTAL, maximum = 25000,value=5000)\n",
    "    # progress.pack()\n",
    "    \n",
    "    #dummy index to provide names to output files\n",
    "    save_img_ind = 0\n",
    "    for step in range(num_steps):\n",
    "        #get the network output\n",
    "        # progress['value']=step+1000\n",
    "        output = net(noise)\n",
    "        #we are only concerned with the output where we have the image available.\n",
    "        masked_output = output*mask\n",
    "        # calculate the l2_loss over the masked output and take an optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.sum((masked_output - deconstructed)**2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('At step {}, loss is {}'.format(step, loss.data.cpu()))\n",
    "        #every save_frequency steps, save a jpg\n",
    "        if step % save_frequency == 0:\n",
    "            tensor_to_jpg(output.data,output_name+'_{}.jpg'.format(save_img_ind))\n",
    "            save_img_ind += 1\n",
    "        if use_cuda:\n",
    "            noise.data += sigma*torch.randn(noise.shape).cuda()\n",
    "        else:\n",
    "            noise.data += sigma*torch.randn(noise.shape)\n",
    "    #clean up any mess we're leaving on the gpu\n",
    "    if use_cuda:\n",
    "        torch.cuda.empty_cache()\n",
    "    # pgbar.mainloop()\n",
    "\n",
    "root = Tk()\n",
    "root.geometry('400x400') \n",
    "btn = Button(root, text = 'Choose File', command = openfile)\n",
    "btn.pack()\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
